{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c907e",
   "metadata": {
    "id": "eb2c907e"
   },
   "outputs": [],
   "source": [
    "seed = 3906303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ad3916",
   "metadata": {
    "id": "69ad3916"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "import glob, os\n",
    "import gzip\n",
    "import random\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Q0dcCNGyjJc",
   "metadata": {
    "id": "8Q0dcCNGyjJc"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4WNxIlW8syto",
   "metadata": {
    "id": "4WNxIlW8syto"
   },
   "source": [
    "Here we read in all the measurement files created in the datagen notebook. Each dataframe is a separate file, which is each a separate table of measurement readings of particular types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fvVZ1hJdg8s1",
   "metadata": {
    "id": "fvVZ1hJdg8s1"
   },
   "outputs": [],
   "source": [
    "# Create dictionary of measurement-type dataframes\n",
    "MEAS = {\n",
    "    name: pd.read_csv(\n",
    "        fp,\n",
    "        parse_dates=['charttime'],       # parsed dates on the fly\n",
    "        low_memory=False                 # avoids mixed-type warnings\n",
    "    )\n",
    "    for fp  in sorted(glob.glob('Datagen/*_filtered_chartevents.csv'))\n",
    "    for name in [os.path.basename(fp).split('_')[0]]\n",
    "}\n",
    "\n",
    "FEATURES = list(MEAS.keys())\n",
    "F        = len(FEATURES)             # number of features\n",
    "GLU_IDX  = FEATURES.index('bg')     # which column contains glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6HaTFPFvJ4M",
   "metadata": {
    "id": "f6HaTFPFvJ4M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abpm', 'bg', 'cvp', 'f', 'hr', 'hrh', 'hrl', 'nbpm', 'rr', 'spo2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YwrUFnBPe0r_",
   "metadata": {
    "id": "YwrUFnBPe0r_"
   },
   "source": [
    "# Data filtering and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBaoX7aRuqyO",
   "metadata": {
    "id": "pBaoX7aRuqyO"
   },
   "source": [
    "Below we filter impossible values for the physiological features. No negative numbers, except for rare cases of CVP feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KRz4MR5FQcZu",
   "metadata": {
    "id": "KRz4MR5FQcZu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abpm: kept 3,094,749 rows  (dropped 0 NaNs / impossible)\n",
      "bg: kept 1,814,111 rows  (dropped 0 NaNs / impossible)\n",
      "cvp: kept 992,340 rows  (dropped 0 NaNs / impossible)\n",
      "f: kept 2,055,038 rows  (dropped 0 NaNs / impossible)\n",
      "hr: kept 8,752,066 rows  (dropped 0 NaNs / impossible)\n",
      "hrh: kept 843,381 rows  (dropped 0 NaNs / impossible)\n",
      "hrl: kept 843,692 rows  (dropped 0 NaNs / impossible)\n",
      "nbpm: kept 5,372,920 rows  (dropped 0 NaNs / impossible)\n",
      "rr: kept 8,636,655 rows  (dropped 0 NaNs / impossible)\n",
      "spo2: kept 8,566,844 rows  (dropped 0 NaNs / impossible)\n"
     ]
    }
   ],
   "source": [
    "#  Per-variable rules. Only reject impossible numbers\n",
    "LOGIC_RULES = {\n",
    "    'bg' : lambda s: (s >= 10) & (s <= 2656),         # historically recorded extreme mg/dL\n",
    "    'hr'  : lambda s: s >= 0,                     # beats / min\n",
    "    'rr'  : lambda s: s >= 0,                     # breaths / min\n",
    "    'spo2': lambda s: (s >= 0) & (s <= 100),      # % saturation\n",
    "    'nbpm': lambda s: s >= 0,                     # mm Hg\n",
    "    'abpm': lambda s: s >= 0,                     # mm Hg\n",
    "    'f'   : lambda s: s >= 0,                     # F < 0 impossible\n",
    "    # CVP can dip a few mm Hg negative during inspiration\n",
    "    'cvp' : lambda s: s >= -5,                    # allow mild physio negative\n",
    "    'hrl' : lambda s: s >= 0,\n",
    "    'hrh' : lambda s: s >= 0,\n",
    "}\n",
    "\n",
    "def filter_impossible(df, short_name):\n",
    "    df = df.copy()\n",
    "    rule = LOGIC_RULES.get(short_name)\n",
    "    if rule is None:\n",
    "        raise KeyError(f\"No logic rule defined for '{short_name}'\")\n",
    "    return df[rule(df['value'])]\n",
    "\n",
    "# Apply to every dataframe in the MEAS dict\n",
    "MEAS_CLEAN = {\n",
    "    name: filter_impossible(df, name)\n",
    "    for name, df in MEAS.items()\n",
    "}\n",
    "\n",
    "# sanity check\n",
    "for name, df in MEAS_CLEAN.items():\n",
    "    bad = df['value'].isna().sum()\n",
    "    print(f\"{name}: kept {len(df):,} rows  (dropped {bad:,} NaNs / impossible)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3b772",
   "metadata": {
    "id": "f4b3b772"
   },
   "source": [
    "# Split Dataset into Training, Validation and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "OZjtGiJgoJMd",
   "metadata": {
    "id": "OZjtGiJgoJMd"
   },
   "outputs": [],
   "source": [
    "unique_subjects = MEAS['bg']['subject_id'].unique()\n",
    "train_subjects, test_subjects = train_test_split(unique_subjects, test_size=0.2,\n",
    "                                         random_state=seed)\n",
    "train_subjects, val_subjects  = train_test_split(train_subjects, test_size=0.25,\n",
    "                                         random_state=seed)\n",
    "\n",
    "SPLIT = {'train': train_subjects, 'val': val_subjects, 'test': test_subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NUT5LDDo3wjh",
   "metadata": {
    "id": "NUT5LDDo3wjh"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "MiIWHZzSyBeM",
   "metadata": {
    "id": "MiIWHZzSyBeM"
   },
   "outputs": [],
   "source": [
    "FREQ       = '2H'           # 2-hour bins\n",
    "MAX_HOURS  = 48\n",
    "STEPS      = MAX_HOURS // 2 # 48 h รท 2 h = 24 bins\n",
    "L          = 6               # look-back  steps (12 hours of history)\n",
    "H          = 1               # look-ahead steps (direct subsequent prediction)\n",
    "SENTINEL   = -999.0            # value the Masking layer will ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WI9SjVB8yB9q",
   "metadata": {
    "id": "WI9SjVB8yB9q"
   },
   "source": [
    "### Here we resample the data to ensure there is a row for every timestep interval of 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "JSTWAz_gx9Dh",
   "metadata": {
    "id": "JSTWAz_gx9Dh"
   },
   "outputs": [],
   "source": [
    "def resample_stay_multi(stay_id, dfs_by_feat):\n",
    "\n",
    "    mat = np.full((STEPS, F), np.nan, dtype='float32')\n",
    "\n",
    "    # Find earliest timestamp amongst all features\n",
    "    start_time = None\n",
    "    # Visit all feature dataframes one by one, and keep track of earliest recorded time\n",
    "    for df in dfs_by_feat.values():\n",
    "        s = df.loc[df['stay_id'] == stay_id, 'charttime']\n",
    "        if not s.empty:\n",
    "            t0 = s.min()\n",
    "            start_time = t0 if start_time is None else min(start_time, t0)\n",
    "\n",
    "    # Return None if none of the feature dfs have the stay_id\n",
    "    if start_time is None:\n",
    "        return None\n",
    "\n",
    "    # Standardise horizon length of icu stay measurements\n",
    "    horizon = pd.date_range(start=start_time.floor(FREQ),\n",
    "                            periods=STEPS,\n",
    "                            freq=FREQ)\n",
    "\n",
    "    # Fill one column of matrix per feature\n",
    "    for j, feat in enumerate(FEATURES):\n",
    "        g = dfs_by_feat[feat]\n",
    "        g = g[g['stay_id'] == stay_id]\n",
    "        if g.empty:\n",
    "          # Column remains NaNs\n",
    "            continue\n",
    "        s = (g.set_index('charttime')['value']\n",
    "               .resample(FREQ).mean())\n",
    "        # reindex sets length of values to be exactly STEPS length long,\n",
    "        # by trancating or padding with NaNs\n",
    "        mat[:, j] = s.reindex(horizon).values\n",
    "\n",
    "    return mat                       # (STEPS, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2cedc",
   "metadata": {
    "id": "aed2cedc"
   },
   "source": [
    "Here we create the data to be fed into the model. Each row of data in the X datasets is a sequence of BG measurements. The Y datasets contain a BG reading that follows directly from that sequence after.\n",
    "\n",
    "The approach we took is so that a sequence of measurements (starting from the first) is created of certain length from each ICU admission, which is taken as the X, and the following value after the sequence is taken as the Y. Then the window is slid over by one so that the sequence is slightly different, creating a new X value and a new following Y value. This process is repeated until the end of the ICU admission measurement sequence is reached, then a new ICU admission is chosen, until all ICU admissions have had their sequences recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9JFB1xgjyNQM",
   "metadata": {
    "id": "9JFB1xgjyNQM"
   },
   "outputs": [],
   "source": [
    "def make_Xy_multi(subj_ids, fit_scaler=False, scaler_dict=None):\n",
    "    X_stays = []\n",
    "\n",
    "    # Create dictionary of all feature dataframes for the current split\n",
    "    dfs_by_feat = {}\n",
    "    for feat, df in MEAS.items():\n",
    "        df_ = df[df['subject_id'].isin(subj_ids)].copy()\n",
    "        df_['charttime'] = pd.to_datetime(df_['charttime'])\n",
    "        dfs_by_feat[feat] = df_\n",
    "\n",
    "    # Retrieve all unique stay_ids across all feature dataframes\n",
    "    all_stays = pd.concat([d[['stay_id']] for d in dfs_by_feat.values()]\n",
    "                          ).drop_duplicates()['stay_id'].values\n",
    "    # Creates a list of (STEPS, F) matrices\n",
    "    for sid in all_stays:\n",
    "        M = resample_stay_multi(sid, dfs_by_feat)   # (STEPS, F) or None\n",
    "        # Only append the matrix if at least one of the dataframes contains a value\n",
    "        if M is not None:\n",
    "            X_stays.append(M)\n",
    "\n",
    "    # Convert to list of stays to 3D tensor shape\n",
    "    X_stays = np.stack(X_stays)          # (N_stays, STEPS, F)\n",
    "\n",
    "    # Feature-wise Standardisation\n",
    "    if scaler_dict is None:\n",
    "        scaler_dict = {}\n",
    "    for j in range(F):\n",
    "        # Concatenate all feature j columns across all stays, include every row, stack them\n",
    "        col = X_stays[:, :, j].ravel()\n",
    "        # NaN mask\n",
    "        mask = ~np.isnan(col)\n",
    "        if fit_scaler:\n",
    "            mu = np.nanmean(col)\n",
    "            sd = np.nanstd(col)\n",
    "            # Protects program from division-by-zero error by ensuring if col is all NaNs, 0 is replaced with 1\n",
    "            sd = sd if sd != 0 else 1.0\n",
    "            scaler_dict[j] = (mu, sd)\n",
    "        # Retrieves values for std and mean for when non-training splits are scaled\n",
    "        mu, sd = scaler_dict[j]\n",
    "        # Scales non-NaN data\n",
    "        col[mask] = (col[mask] - mu) / sd\n",
    "\n",
    "        # Sets a slice of dimension (X_stays.shape[0], STEPS) of a particular feature to the col variable\n",
    "        X_stays[:, :, j] = col.reshape(X_stays.shape[0], STEPS)\n",
    "\n",
    "    # Sliding window\n",
    "    windows, targets = [], []\n",
    "    for stay in X_stays:\n",
    "        # Window slides across every point so that the entire horizon of the ICU stay is included once\n",
    "        for t0 in range(0, STEPS - L - H + 1):\n",
    "            x_win = stay[t0 : t0 + L, :]                # Look-back window\n",
    "            y_val = stay[t0 + L + H - 1, GLU_IDX]       # Glucose value following window\n",
    "            if not np.isnan(y_val):                     # ensure that the final y value is an actual value\n",
    "                windows.append(x_win)\n",
    "                targets.append(y_val)\n",
    "\n",
    "    X = np.array(windows, dtype='float32')             # (N, L, F)\n",
    "    y = np.array(targets, dtype='float32')             # (N,)\n",
    "\n",
    "    # mask NaN timesteps\n",
    "    X[np.isnan(X)] = SENTINEL\n",
    "    return X, y, scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc3a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Pickles', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "p2166dlHEGBg",
   "metadata": {
    "id": "p2166dlHEGBg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train set -> 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, SCALERS = make_Xy_multi(SPLIT['train'], fit_scaler=True)\n",
    "\n",
    "# Save train data and scalers immediately\n",
    "train_path = 'Pickles/glu_train.pkl.gz'\n",
    "with gzip.open(train_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'scalers': SCALERS\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved train set -> {os.path.getsize(train_path)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "G-JcyoOjERA-",
   "metadata": {
    "id": "G-JcyoOjERA-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation set -> 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val, _ = make_Xy_multi(SPLIT['val'], scaler_dict=SCALERS)\n",
    "\n",
    "# Save val data immediately\n",
    "val_path = 'Pickles/glu_val.pkl.gz'\n",
    "with gzip.open(val_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved validation set -> {os.path.getsize(val_path)/1e6:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cvTuKx1bEWvS",
   "metadata": {
    "id": "cvTuKx1bEWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test set -> 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test, _ = make_Xy_multi(SPLIT['test'], scaler_dict=SCALERS)\n",
    "\n",
    "# Save test data immediately\n",
    "test_path = 'Pickles/glu_test.pkl.gz'\n",
    "with gzip.open(test_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved test set -> {os.path.getsize(test_path)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpw64X9xEnru",
   "metadata": {
    "id": "kpw64X9xEnru"
   },
   "source": [
    "# Load saved tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "QBh6HaMhEtF5",
   "metadata": {
    "id": "QBh6HaMhEtF5"
   },
   "outputs": [],
   "source": [
    "train_path = 'Pickles/glu_train.pkl.gz'\n",
    "\n",
    "with gzip.open(train_path, 'rb') as f:\n",
    "    train_bundle = pickle.load(f)\n",
    "\n",
    "X_train = train_bundle['X_train']\n",
    "y_train = train_bundle['y_train']\n",
    "SCALERS = train_bundle['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DGMxmVcsE14m",
   "metadata": {
    "id": "DGMxmVcsE14m"
   },
   "outputs": [],
   "source": [
    "val_path = 'Pickles/glu_val.pkl.gz'\n",
    "\n",
    "with gzip.open(val_path, 'rb') as f:\n",
    "    val_bundle = pickle.load(f)\n",
    "\n",
    "X_val = val_bundle['X_val']\n",
    "y_val = val_bundle['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hjza6T_BE32B",
   "metadata": {
    "id": "hjza6T_BE32B"
   },
   "outputs": [],
   "source": [
    "test_path = 'Pickles/glu_test.pkl.gz'\n",
    "\n",
    "with gzip.open(test_path, 'rb') as f:\n",
    "    test_bundle = pickle.load(f)\n",
    "\n",
    "X_test = test_bundle['X_test']\n",
    "y_test = test_bundle['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_f-DqBTk7f7H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f-DqBTk7f7H",
    "outputId": "f572d210-9416-459d-b8b5-be1f865d5d90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7a0679aeab02>:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  horizon = pd.date_range(start=start_time.floor(FREQ),\n",
      "<ipython-input-9-7a0679aeab02>:31: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(FREQ).mean())\n",
      "<ipython-input-9-7a0679aeab02>:19: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  horizon = pd.date_range(start=start_time.floor(FREQ),\n",
      "<ipython-input-9-7a0679aeab02>:31: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(FREQ).mean())\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, SCALERS = make_Xy_multi(SPLIT['train'], fit_scaler=True)\n",
    "X_val,   y_val,  _        = make_Xy_multi(SPLIT['val'],   scaler_dict=SCALERS)\n",
    "X_test,  y_test, _        = make_Xy_multi(SPLIT['test'],  scaler_dict=SCALERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "myv077YiwTuS",
   "metadata": {
    "id": "myv077YiwTuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose  ฮผ=246.7  ฯ=9512.7\n"
     ]
    }
   ],
   "source": [
    "# After you build SCALERS in make_Xy_multi(...)\n",
    "mu_glu, std_glu = SCALERS[GLU_IDX]          # ฮผ, ฯ learned by StandardScaler\n",
    "print(f\"Glucose  ฮผ={mu_glu:.1f}  ฯ={std_glu:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "EFRdNVBm_C1Z",
   "metadata": {
    "id": "EFRdNVBm_C1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (255182, 6, 10) (255182,)\n",
      "Val  : (85902, 6, 10) (85902,)\n",
      "Test : (84769, 6, 10) (84769,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val  :\", X_val.shape,   y_val.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "EdDbLesv5Hdy",
   "metadata": {
    "id": "EdDbLesv5Hdy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN in y_train ? False\n",
      "Any NaN in X_train ? False\n",
      "NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Any NaN in y_train ?\", np.isnan(y_train).any())\n",
    "print(\"Any NaN in X_train ?\", np.isnan(X_train).any())\n",
    "\n",
    "# How many?\n",
    "print(\"NaN count:\", np.isnan(X_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "USMpFcAiLKOE",
   "metadata": {
    "id": "USMpFcAiLKOE"
   },
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "def make_ds(X, y, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(y), seed=seed)\n",
    "    return ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gZXuchmOLMf5",
   "metadata": {
    "id": "gZXuchmOLMf5"
   },
   "outputs": [],
   "source": [
    "ds_train = make_ds(X_train, y_train, shuffle=True)\n",
    "ds_val   = make_ds(X_val,   y_val,   shuffle=False)\n",
    "ds_test  = make_ds(X_test,  y_test,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27DSFKlALWUJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "27DSFKlALWUJ",
    "outputId": "7a85fc99-c884-4c41-82e2-f0248ab6c99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 6, 10)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                19200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=SENTINEL, input_shape=(L, F)),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    # A dense layer here is necessary, as each hidden state output, which is\n",
    "    # the output of an LSTM unit is only within the range of a tanh activation function,\n",
    "    # so further transformation is needed\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)                   # regression\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae', RootMeanSquaredError(name='rmse'), 'mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iCItqTtdO1sS",
   "metadata": {
    "id": "iCItqTtdO1sS"
   },
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yfy1ukOPLYTR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfy1ukOPLYTR",
    "outputId": "7e65fdc0-b857-4785-c00f-661b0207ed1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6996 - mae: 0.0349 - rmse: 0.8364 - mse: 0.6996\n",
      "Epoch 1: saving model to models\\multivar_epoch_01.h5\n",
      "3988/3988 [==============================] - 18s 4ms/step - loss: 0.6994 - mae: 0.0349 - rmse: 0.8363 - mse: 0.6994 - val_loss: 0.3442 - val_mae: 0.0163 - val_rmse: 0.5867 - val_mse: 0.3442\n",
      "Epoch 2/100\n",
      "3978/3988 [============================>.] - ETA: 0s - loss: 0.6995 - mae: 0.0252 - rmse: 0.8364 - mse: 0.6995\n",
      "Epoch 2: saving model to models\\multivar_epoch_02.h5\n",
      "3988/3988 [==============================] - 16s 4ms/step - loss: 0.6979 - mae: 0.0252 - rmse: 0.8354 - mse: 0.6979 - val_loss: 0.3440 - val_mae: 0.0148 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 3/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0229 - rmse: 0.8355 - mse: 0.6980\n",
      "Epoch 3: saving model to models\\multivar_epoch_03.h5\n",
      "3988/3988 [==============================] - 17s 4ms/step - loss: 0.6976 - mae: 0.0229 - rmse: 0.8352 - mse: 0.6976 - val_loss: 0.3439 - val_mae: 0.0120 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 4/100\n",
      "3980/3988 [============================>.] - ETA: 0s - loss: 0.6989 - mae: 0.0206 - rmse: 0.8360 - mse: 0.6989\n",
      "Epoch 4: saving model to models\\multivar_epoch_04.h5\n",
      "3988/3988 [==============================] - 18s 4ms/step - loss: 0.6976 - mae: 0.0206 - rmse: 0.8352 - mse: 0.6976 - val_loss: 0.3465 - val_mae: 0.0576 - val_rmse: 0.5886 - val_mse: 0.3465\n",
      "Epoch 5/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0220 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 5: saving model to models\\multivar_epoch_05.h5\n",
      "3988/3988 [==============================] - 18s 5ms/step - loss: 0.6976 - mae: 0.0220 - rmse: 0.8352 - mse: 0.6976 - val_loss: 0.3439 - val_mae: 0.0112 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 6/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0197 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 6: saving model to models\\multivar_epoch_06.h5\n",
      "3988/3988 [==============================] - 18s 5ms/step - loss: 0.6974 - mae: 0.0197 - rmse: 0.8351 - mse: 0.6974 - val_loss: 0.3441 - val_mae: 0.0226 - val_rmse: 0.5866 - val_mse: 0.3441\n",
      "Epoch 7/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6977 - mae: 0.0180 - rmse: 0.8353 - mse: 0.6977\n",
      "Epoch 7: saving model to models\\multivar_epoch_07.h5\n",
      "3988/3988 [==============================] - 19s 5ms/step - loss: 0.6973 - mae: 0.0180 - rmse: 0.8351 - mse: 0.6973 - val_loss: 0.3439 - val_mae: 0.0105 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 8/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0174 - rmse: 0.8353 - mse: 0.6976\n",
      "Epoch 8: saving model to models\\multivar_epoch_08.h5\n",
      "3988/3988 [==============================] - 19s 5ms/step - loss: 0.6973 - mae: 0.0174 - rmse: 0.8350 - mse: 0.6973 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 9/100\n",
      "3979/3988 [============================>.] - ETA: 0s - loss: 0.6988 - mae: 0.0176 - rmse: 0.8359 - mse: 0.6988\n",
      "Epoch 9: saving model to models\\multivar_epoch_09.h5\n",
      "3988/3988 [==============================] - 19s 5ms/step - loss: 0.6973 - mae: 0.0176 - rmse: 0.8351 - mse: 0.6973 - val_loss: 0.3439 - val_mae: 0.0117 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 10/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0166 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 10: saving model to models\\multivar_epoch_10.h5\n",
      "3988/3988 [==============================] - 20s 5ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0128 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 11/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0168 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 11: saving model to models\\multivar_epoch_11.h5\n",
      "3988/3988 [==============================] - 21s 5ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 12/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 12: saving model to models\\multivar_epoch_12.h5\n",
      "3988/3988 [==============================] - 22s 5ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0177 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 13/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0166 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 13: saving model to models\\multivar_epoch_13.h5\n",
      "3988/3988 [==============================] - 24s 6ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0142 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 14/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0168 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 14: saving model to models\\multivar_epoch_14.h5\n",
      "3988/3988 [==============================] - 24s 6ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 15/100\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 0.6983 - mae: 0.0167 - rmse: 0.8357 - mse: 0.6983\n",
      "Epoch 15: saving model to models\\multivar_epoch_15.h5\n",
      "3988/3988 [==============================] - 24s 6ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0088 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 16/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0163 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 16: saving model to models\\multivar_epoch_16.h5\n",
      "3988/3988 [==============================] - 25s 6ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3438 - val_mae: 0.0112 - val_rmse: 0.5864 - val_mse: 0.3438\n",
      "Epoch 17/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6979 - mae: 0.0167 - rmse: 0.8354 - mse: 0.6979\n",
      "Epoch 17: saving model to models\\multivar_epoch_17.h5\n",
      "3988/3988 [==============================] - 30s 8ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0217 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 18/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0161 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 18: saving model to models\\multivar_epoch_18.h5\n",
      "3988/3988 [==============================] - 29s 7ms/step - loss: 0.6972 - mae: 0.0161 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3442 - val_mae: 0.0272 - val_rmse: 0.5867 - val_mse: 0.3442\n",
      "Epoch 19/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0172 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 19: saving model to models\\multivar_epoch_19.h5\n",
      "3988/3988 [==============================] - 28s 7ms/step - loss: 0.6972 - mae: 0.0172 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0126 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 20/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0168 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 20: saving model to models\\multivar_epoch_20.h5\n",
      "3988/3988 [==============================] - 31s 8ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0088 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 21/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 21: saving model to models\\multivar_epoch_21.h5\n",
      "3988/3988 [==============================] - 30s 7ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3441 - val_mae: 0.0236 - val_rmse: 0.5866 - val_mse: 0.3441\n",
      "Epoch 22/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0168 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 22: saving model to models\\multivar_epoch_22.h5\n",
      "3988/3988 [==============================] - 32s 8ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3982/3988 [============================>.] - ETA: 0s - loss: 0.6981 - mae: 0.0168 - rmse: 0.8355 - mse: 0.6981\n",
      "Epoch 23: saving model to models\\multivar_epoch_23.h5\n",
      "3988/3988 [==============================] - 31s 8ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0087 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 24/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0165 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 24: saving model to models\\multivar_epoch_24.h5\n",
      "3988/3988 [==============================] - 31s 8ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0099 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 25/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0165 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 25: saving model to models\\multivar_epoch_25.h5\n",
      "3988/3988 [==============================] - 33s 8ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0131 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 26/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0167 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 26: saving model to models\\multivar_epoch_26.h5\n",
      "3988/3988 [==============================] - 31s 8ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0091 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 27/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 27: saving model to models\\multivar_epoch_27.h5\n",
      "3988/3988 [==============================] - 31s 8ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0170 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 28/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0167 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 28: saving model to models\\multivar_epoch_28.h5\n",
      "3988/3988 [==============================] - 32s 8ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0160 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 29/100\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 0.6981 - mae: 0.0167 - rmse: 0.8355 - mse: 0.6981\n",
      "Epoch 29: saving model to models\\multivar_epoch_29.h5\n",
      "3988/3988 [==============================] - 32s 8ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0128 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 30/100\n",
      "3981/3988 [============================>.] - ETA: 0s - loss: 0.6983 - mae: 0.0167 - rmse: 0.8356 - mse: 0.6983\n",
      "Epoch 30: saving model to models\\multivar_epoch_30.h5\n",
      "3988/3988 [==============================] - 32s 8ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3438 - val_mae: 0.0108 - val_rmse: 0.5864 - val_mse: 0.3438\n",
      "Epoch 31/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 31: saving model to models\\multivar_epoch_31.h5\n",
      "3988/3988 [==============================] - 36s 9ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0129 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 32/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0165 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 32: saving model to models\\multivar_epoch_32.h5\n",
      "3988/3988 [==============================] - 35s 9ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3438 - val_mae: 0.0106 - val_rmse: 0.5864 - val_mse: 0.3438\n",
      "Epoch 33/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0166 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 33: saving model to models\\multivar_epoch_33.h5\n",
      "3988/3988 [==============================] - 33s 8ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3438 - val_mae: 0.0106 - val_rmse: 0.5864 - val_mse: 0.3438\n",
      "Epoch 34/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0164 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 34: saving model to models\\multivar_epoch_34.h5\n",
      "3988/3988 [==============================] - 35s 9ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 35/100\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 0.6981 - mae: 0.0166 - rmse: 0.8355 - mse: 0.6981\n",
      "Epoch 35: saving model to models\\multivar_epoch_35.h5\n",
      "3988/3988 [==============================] - 34s 8ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0097 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 36/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0164 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 36: saving model to models\\multivar_epoch_36.h5\n",
      "3988/3988 [==============================] - 38s 9ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0089 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 37/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0165 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 37: saving model to models\\multivar_epoch_37.h5\n",
      "3988/3988 [==============================] - 39s 10ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0189 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 38/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0168 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 38: saving model to models\\multivar_epoch_38.h5\n",
      "3988/3988 [==============================] - 40s 10ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0185 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 39/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0167 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 39: saving model to models\\multivar_epoch_39.h5\n",
      "3988/3988 [==============================] - 39s 10ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3438 - val_mae: 0.0106 - val_rmse: 0.5864 - val_mse: 0.3438\n",
      "Epoch 40/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0159 - rmse: 0.8355 - mse: 0.6980\n",
      "Epoch 40: saving model to models\\multivar_epoch_40.h5\n",
      "3988/3988 [==============================] - 40s 10ms/step - loss: 0.6972 - mae: 0.0159 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0230 - val_rmse: 0.5866 - val_mse: 0.3440\n",
      "Epoch 41/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 41: saving model to models\\multivar_epoch_41.h5\n",
      "3988/3988 [==============================] - 38s 9ms/step - loss: 0.6973 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6973 - val_loss: 0.3439 - val_mae: 0.0140 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 42/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0163 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 42: saving model to models\\multivar_epoch_42.h5\n",
      "3988/3988 [==============================] - 37s 9ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0147 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 43/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0165 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 43: saving model to models\\multivar_epoch_43.h5\n",
      "3988/3988 [==============================] - 35s 9ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0097 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 44/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0159 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 44: saving model to models\\multivar_epoch_44.h5\n",
      "3988/3988 [==============================] - 39s 10ms/step - loss: 0.6972 - mae: 0.0159 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3442 - val_mae: 0.0287 - val_rmse: 0.5867 - val_mse: 0.3442\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0169 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 45: saving model to models\\multivar_epoch_45.h5\n",
      "3988/3988 [==============================] - 40s 10ms/step - loss: 0.6972 - mae: 0.0169 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0128 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 46/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0170 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 46: saving model to models\\multivar_epoch_46.h5\n",
      "3988/3988 [==============================] - 37s 9ms/step - loss: 0.6972 - mae: 0.0170 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0092 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 47/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0163 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 47: saving model to models\\multivar_epoch_47.h5\n",
      "3988/3988 [==============================] - 44s 11ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0141 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 48/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0165 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 48: saving model to models\\multivar_epoch_48.h5\n",
      "3988/3988 [==============================] - 37s 9ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0180 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 49/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0169 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 49: saving model to models\\multivar_epoch_49.h5\n",
      "3988/3988 [==============================] - 36s 9ms/step - loss: 0.6972 - mae: 0.0169 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0088 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 50/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 50: saving model to models\\multivar_epoch_50.h5\n",
      "3988/3988 [==============================] - 38s 10ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0100 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 51/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 51: saving model to models\\multivar_epoch_51.h5\n",
      "3988/3988 [==============================] - 39s 10ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0123 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 52/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0162 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 52: saving model to models\\multivar_epoch_52.h5\n",
      "3988/3988 [==============================] - 41s 10ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3441 - val_mae: 0.0246 - val_rmse: 0.5866 - val_mse: 0.3441\n",
      "Epoch 53/100\n",
      "3982/3988 [============================>.] - ETA: 0s - loss: 0.6981 - mae: 0.0170 - rmse: 0.8355 - mse: 0.6981\n",
      "Epoch 53: saving model to models\\multivar_epoch_53.h5\n",
      "3988/3988 [==============================] - 41s 10ms/step - loss: 0.6972 - mae: 0.0170 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0088 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 54/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 54: saving model to models\\multivar_epoch_54.h5\n",
      "3988/3988 [==============================] - 42s 10ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0088 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 55/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 55: saving model to models\\multivar_epoch_55.h5\n",
      "3988/3988 [==============================] - 46s 11ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0151 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 56/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0165 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 56: saving model to models\\multivar_epoch_56.h5\n",
      "3988/3988 [==============================] - 45s 11ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0126 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 57/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0163 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 57: saving model to models\\multivar_epoch_57.h5\n",
      "3988/3988 [==============================] - 43s 11ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0216 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 58/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0163 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 58: saving model to models\\multivar_epoch_58.h5\n",
      "3988/3988 [==============================] - 44s 11ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0185 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 59/100\n",
      "3983/3988 [============================>.] - ETA: 0s - loss: 0.6980 - mae: 0.0169 - rmse: 0.8354 - mse: 0.6980\n",
      "Epoch 59: saving model to models\\multivar_epoch_59.h5\n",
      "3988/3988 [==============================] - 42s 11ms/step - loss: 0.6972 - mae: 0.0169 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0101 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 60/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 60: saving model to models\\multivar_epoch_60.h5\n",
      "3988/3988 [==============================] - 48s 12ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0100 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 61/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0161 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 61: saving model to models\\multivar_epoch_61.h5\n",
      "3988/3988 [==============================] - 46s 11ms/step - loss: 0.6972 - mae: 0.0161 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3445 - val_mae: 0.0342 - val_rmse: 0.5869 - val_mse: 0.3445\n",
      "Epoch 62/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0171 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 62: saving model to models\\multivar_epoch_62.h5\n",
      "3988/3988 [==============================] - 46s 11ms/step - loss: 0.6972 - mae: 0.0171 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0138 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 63/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6975 - mae: 0.0165 - rmse: 0.8351 - mse: 0.6975\n",
      "Epoch 63: saving model to models\\multivar_epoch_63.h5\n",
      "3988/3988 [==============================] - 49s 12ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0159 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 64/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 64: saving model to models\\multivar_epoch_64.h5\n",
      "3988/3988 [==============================] - 45s 11ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0205 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 65/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0162 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 65: saving model to models\\multivar_epoch_65.h5\n",
      "3988/3988 [==============================] - 51s 13ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3441 - val_mae: 0.0240 - val_rmse: 0.5866 - val_mse: 0.3441\n",
      "Epoch 66/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 66: saving model to models\\multivar_epoch_66.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3444 - val_mae: 0.0319 - val_rmse: 0.5868 - val_mse: 0.3444\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0170 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 67: saving model to models\\multivar_epoch_67.h5\n",
      "3988/3988 [==============================] - 58s 15ms/step - loss: 0.6972 - mae: 0.0170 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0104 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 68/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0164 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 68: saving model to models\\multivar_epoch_68.h5\n",
      "3988/3988 [==============================] - 55s 14ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0094 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 69/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0159 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 69: saving model to models\\multivar_epoch_69.h5\n",
      "3988/3988 [==============================] - 61s 15ms/step - loss: 0.6972 - mae: 0.0160 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3445 - val_mae: 0.0352 - val_rmse: 0.5870 - val_mse: 0.3445\n",
      "Epoch 70/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6543 - mae: 0.0162 - rmse: 0.8089 - mse: 0.6543\n",
      "Epoch 70: saving model to models\\multivar_epoch_70.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0200 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 71/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0169 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 71: saving model to models\\multivar_epoch_71.h5\n",
      "3988/3988 [==============================] - 48s 12ms/step - loss: 0.6972 - mae: 0.0169 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0097 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 72/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0162 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 72: saving model to models\\multivar_epoch_72.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0220 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 73/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0166 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 73: saving model to models\\multivar_epoch_73.h5\n",
      "3988/3988 [==============================] - 56s 14ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0093 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 74/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 74: saving model to models\\multivar_epoch_74.h5\n",
      "3988/3988 [==============================] - 58s 15ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0123 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 75/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 75: saving model to models\\multivar_epoch_75.h5\n",
      "3988/3988 [==============================] - 55s 14ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0142 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 76/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0168 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 76: saving model to models\\multivar_epoch_76.h5\n",
      "3988/3988 [==============================] - 57s 14ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 77/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 77: saving model to models\\multivar_epoch_77.h5\n",
      "3988/3988 [==============================] - 65s 16ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0130 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 78/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 78: saving model to models\\multivar_epoch_78.h5\n",
      "3988/3988 [==============================] - 58s 14ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0094 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 79/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0167 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 79: saving model to models\\multivar_epoch_79.h5\n",
      "3988/3988 [==============================] - 58s 14ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0089 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 80/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6975 - mae: 0.0163 - rmse: 0.8351 - mse: 0.6975\n",
      "Epoch 80: saving model to models\\multivar_epoch_80.h5\n",
      "3988/3988 [==============================] - 56s 14ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0089 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 81/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0165 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 81: saving model to models\\multivar_epoch_81.h5\n",
      "3988/3988 [==============================] - 57s 14ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0136 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 82/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0163 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 82: saving model to models\\multivar_epoch_82.h5\n",
      "3988/3988 [==============================] - 59s 15ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0155 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 83/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0166 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 83: saving model to models\\multivar_epoch_83.h5\n",
      "3988/3988 [==============================] - 56s 14ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0199 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 84/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0167 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 84: saving model to models\\multivar_epoch_84.h5\n",
      "3988/3988 [==============================] - 59s 15ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0160 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 85/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 85: saving model to models\\multivar_epoch_85.h5\n",
      "3988/3988 [==============================] - 58s 15ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0146 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 86/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0167 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 86: saving model to models\\multivar_epoch_86.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0087 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 87/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0166 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 87: saving model to models\\multivar_epoch_87.h5\n",
      "3988/3988 [==============================] - 52s 13ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0167 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 88/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0166 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 88: saving model to models\\multivar_epoch_88.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0095 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0166 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 89: saving model to models\\multivar_epoch_89.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0166 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0099 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 90/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0165 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 90: saving model to models\\multivar_epoch_90.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0210 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 91/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0173 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 91: saving model to models\\multivar_epoch_91.h5\n",
      "3988/3988 [==============================] - 61s 15ms/step - loss: 0.6972 - mae: 0.0173 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0092 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 92/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0165 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 92: saving model to models\\multivar_epoch_92.h5\n",
      "3988/3988 [==============================] - 59s 15ms/step - loss: 0.6972 - mae: 0.0164 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0093 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 93/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 93: saving model to models\\multivar_epoch_93.h5\n",
      "3988/3988 [==============================] - 59s 15ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0161 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 94/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 94: saving model to models\\multivar_epoch_94.h5\n",
      "3988/3988 [==============================] - 63s 16ms/step - loss: 0.6972 - mae: 0.0162 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0144 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 95/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0167 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 95: saving model to models\\multivar_epoch_95.h5\n",
      "3988/3988 [==============================] - 61s 15ms/step - loss: 0.6972 - mae: 0.0167 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0187 - val_rmse: 0.5865 - val_mse: 0.3439\n",
      "Epoch 96/100\n",
      "3984/3988 [============================>.] - ETA: 0s - loss: 0.6978 - mae: 0.0168 - rmse: 0.8353 - mse: 0.6978\n",
      "Epoch 96: saving model to models\\multivar_epoch_96.h5\n",
      "3988/3988 [==============================] - 62s 16ms/step - loss: 0.6972 - mae: 0.0168 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0090 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 97/100\n",
      "3988/3988 [==============================] - ETA: 0s - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972\n",
      "Epoch 97: saving model to models\\multivar_epoch_97.h5\n",
      "3988/3988 [==============================] - 64s 16ms/step - loss: 0.6972 - mae: 0.0163 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3440 - val_mae: 0.0198 - val_rmse: 0.5865 - val_mse: 0.3440\n",
      "Epoch 98/100\n",
      "3986/3988 [============================>.] - ETA: 0s - loss: 0.6974 - mae: 0.0171 - rmse: 0.8351 - mse: 0.6974\n",
      "Epoch 98: saving model to models\\multivar_epoch_98.h5\n",
      "3988/3988 [==============================] - 59s 15ms/step - loss: 0.6972 - mae: 0.0171 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0101 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 99/100\n",
      "3987/3988 [============================>.] - ETA: 0s - loss: 0.6973 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6973\n",
      "Epoch 99: saving model to models\\multivar_epoch_99.h5\n",
      "3988/3988 [==============================] - 60s 15ms/step - loss: 0.6972 - mae: 0.0165 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0157 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "Epoch 100/100\n",
      "3985/3988 [============================>.] - ETA: 0s - loss: 0.6976 - mae: 0.0169 - rmse: 0.8352 - mse: 0.6976\n",
      "Epoch 100: saving model to models\\multivar_epoch_100.h5\n",
      "3988/3988 [==============================] - 62s 15ms/step - loss: 0.6972 - mae: 0.0169 - rmse: 0.8350 - mse: 0.6972 - val_loss: 0.3439 - val_mae: 0.0089 - val_rmse: 0.5864 - val_mse: 0.3439\n",
      "1325/1325 [==============================] - 4s 3ms/step - loss: 0.2607 - mae: 0.0070 - rmse: 0.5106 - mse: 0.2607\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14080\\2128064541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test RMSE = {np.sqrt(test_loss):.2f}   |   MAE = {test_mae:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#  Create a checkpoint callback\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/multivar_epoch_{epoch:02d}.h5',\n",
    "    save_freq='epoch',                        # save after each epoch\n",
    "    save_weights_only=False,                  # save the entire model (architecture + weights + optimizer state)\n",
    "    verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=100,\n",
    "    # Validation is used to determine if model is overfitting\n",
    "    validation_data=ds_val,\n",
    "    callbacks=[ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model.evaluate(ds_test, return_dict=True)\n",
    "print(f\"Test RMSE = {results['rmse']:.2f}   |   MAE = {results['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9daa0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 [==============================] - 3s 2ms/step - loss: 0.2607 - mae: 0.0070 - rmse: 0.5106 - mse: 0.2607\n",
      "Test RMSE = 0.51   |   MAE = 0.01\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(ds_test, return_dict=True)\n",
    "print(f\"Test RMSE = {results['rmse']:.2f}   |   MAE = {results['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aPhIh3THUT5I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPhIh3THUT5I",
    "outputId": "ba185ed0-e338-492d-db9f-c78820c321c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 23590026.00 (mg/dL)^2\n",
      "Test RMSE = 4856.96 mg/dL\n",
      "Test MAE  = 66.28 mg/dL\n"
     ]
    }
   ],
   "source": [
    "y_pred_z = model.predict(ds_test, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred = y_pred_z * std_glu + mu_glu\n",
    "y_true = y_true_z * std_glu + mu_glu\n",
    "\n",
    "# metrics in true units\n",
    "mse  = np.mean((y_true - y_pred) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
